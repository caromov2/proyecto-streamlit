from pathlib import Path

# Texto corregido del README.md
readme_text = """# üåç Traductor Multiling√ºe con Voz

Proyecto elegido: **Traductor multiling√ºe con voz (voz ‚Üí texto ‚Üí traducci√≥n ‚Üí voz)**  

Para el tema de seguridad, he usado `st.secrets` de Streamlit, evitando exponer las claves en el c√≥digo fuente.

Imports necesarios:  
`import streamlit as st`, `import requests`, `from streamlit_mic_recorder import mic_recorder`

## √çndice

1. [Descripci√≥n del Proyecto](#descripci√≥n-del-proyecto)  
2. [Tecnolog√≠as y APIs utilizadas](#tecnolog√≠as-y-apis-utilizadas)  
   - [1. Azure Speech-to-Text (STT)](#1-azure-speech-to-text-stt)  
   - [2. Azure Translator](#2-azure-translator)  
   - [3. Azure Text-to-Speech (TTS)](#3-azure-text-to-speech-tts)  
3. [Funcionalidades de la Aplicaci√≥n](#funcionalidades-de-la-aplicaci√≥n)  
4. [Funcionamiento del C√≥digo](#4-c√≥mo-funciona-el-c√≥digo)

---

## Descripci√≥n del Proyecto

Esta aplicaci√≥n permite a los usuarios grabar o subir un audio y obtener:

1. **Transcripci√≥n del audio a texto**  
2. **Traducci√≥n del texto a otro idioma**  
3. **S√≠ntesis de voz del texto traducido**

El flujo completo se realiza usando **APIs de Azure**, proporcionando un procesamiento de voz y lenguaje r√°pido y confiable.

---

## Tecnolog√≠as y APIs utilizadas

Se han utilizado las APIs de Azure, concretamente:

### 1. Azure Speech-to-Text (STT)
- Convierte la voz en texto usando modelos neuronales de Azure.  
- Permite seleccionar el idioma de origen para mejorar la precisi√≥n.  
- Configuraci√≥n de audio: WAV o WEBM, 16 kHz, PCM.  
- Proporciona transcripci√≥n r√°pida y precisa de contenido hablado.  

### 2. Azure Translator
- Traduce el texto transcrito a cualquier idioma compatible con Azure.  
- Configurado con la versi√≥n `3.0` de la API.  
- Permite traducci√≥n bidireccional manteniendo la coherencia sem√°ntica.  
- Ideal para comunicaci√≥n multiling√ºe instant√°nea.  

### 3. Azure Text-to-Speech (TTS)
- Convierte el texto traducido en voz de alta calidad.  
- Permite elegir la voz y el idioma de salida (por ejemplo, `ElviraNeural`, `JennyNeural`).  
- Genera salida en formato MP3, compatible con la mayor√≠a de plataformas.  
- Facilita la creaci√≥n de contenido accesible y multiling√ºe.  

---

## Funcionalidades de la Aplicaci√≥n

- Interfaz **intuitiva y responsiva** creada con Streamlit.  
- Grabaci√≥n de audio directamente desde el navegador o carga de archivos existentes.  
- Selecci√≥n de idiomas de origen y destino, con voces configurables.  
- Manejo de errores para cada API, mostrando mensajes claros al usuario.  

---

## 4. C√≥mo funciona el c√≥digo

Esta secci√≥n explica c√≥mo se procesa la entrada de audio en la aplicaci√≥n.

![Diagrama del flujo de audio](capturas/captura1.png)

### ‚Äî Selector de idioma ‚Äî
Tenemos dos columnas:  
- **col1**: selector del idioma de origen, con un array de idiomas disponibles.  
- **col2**: selector del idioma de destino.

### ‚Äî Audio ‚Äî
Disponemos de dos columnas con opciones para:
- **Grabar audio** usando `mic_recorder` (que se importa en el c√≥digo).  
- **Subir un archivo** mediante `file_uploader`.

1. Se inicializa `audio_data` como `None`.  
2. Si el usuario sube un archivo, se convierte a bytes y se guarda en `audio_data`.  
   - `uploaded` es el nombre del archivo subido.  
   - `grabacion_data` es la grabaci√≥n realizada con el micr√≥fono.  
3. Si el usuario graba audio con el micr√≥fono, tambi√©n se guarda en `audio_data`.  
4. Se muestra un mensaje de √©xito indicando que el audio est√° listo para procesarse.

![Captura STT, traducci√≥n](capturas/captura2.png)

### ‚Äî STT ‚Äî
Tenemos una condici√≥n `if` donde se ejecuta el bloque solo si `audio_data` contiene algo.

- En `params` definimos los par√°metros de consulta, especificando el idioma de origen y el formato.  
- En `headers_stt` se definen los par√°metros de autenticaci√≥n y tipo de contenido.  
  - En `Content-Type` se indica que el formato es audio WAV con codificaci√≥n PCM a 16.000 Hz.  
  - En `Accept` se especifica que la respuesta ser√° en formato JSON.  
- En `resp` enviamos la solicitud POST con todos los par√°metros.  
- Con `raise_for_status()` comprobamos si hay errores de c√≥digo de estado.  
- Si hay error, se muestra un mensaje en el bloque `except`.  
- Guardamos el contenido devuelto en `data` en formato JSON.  
- Comprobamos si devuelve el texto transcrito; si funciona, se muestra con `st.success()` el texto obtenido del JSON.

---

### ‚Äî Traducci√≥n ‚Äî
En esta secci√≥n enviamos el texto transcrito al servicio de traducci√≥n.

- Para ello usamos `trans_params`, donde especificamos los par√°metros necesarios: versi√≥n de la API, idioma de origen y destino.  
- En el encabezado (`headers`) se env√≠a la clave, la regi√≥n y el formato de salida (JSON).  
- En el `body` se crea el contenido de la solicitud JSON, una lista con un diccionario que contiene el texto a traducir.  
- En `tr_resp` enviamos la solicitud POST.  
- Comprobamos si devuelve alg√∫n error; si el c√≥digo de estado es 200, extraemos del JSON el texto traducido.

![Captura TTS](capturas/captura3.png)

---

### ‚Äî TTS ‚Äî

Aqui en esta seccion queremos enviar el texto traducido para crear un audio con el idioma seleccionado.

ssml = f"""...""": Crea el Speech Synthesis Markup Language (SSML). El SSML es un formato XML que instruye al servicio de TTS sobre c√≥mo debe generarse la voz.

    <speak version='1.0' xml:lang='{codigo_destino}'>: Define el idioma base para la s√≠ntesis, utilizando el c√≥digo del idioma destino.

    <voice name='{voz_destino}'>{texto_tradu}</voice>: Especifica la voz a utilizar (voz_destino) y encierra el texto a leer (texto_tradu).

En el headers_tts enviamos la key el ssml y el formato del audio que es MP3, mono, 16kHz, 128kbps.

enviamos el post en tts_resp y comprovamos el status_code si es igual a 200 sacamos el audio y sinos sacamos el error  
